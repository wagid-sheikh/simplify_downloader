from __future__ import annotations

import argparse
import asyncio
import os
import smtplib
from dataclasses import dataclass
from datetime import date, datetime, timedelta
from email.message import EmailMessage
from pathlib import Path
from typing import Iterable, List, Sequence, Tuple

import sqlalchemy as sa

from common.db import session_scope

from dashboard_downloader.db_tables import documents
from dashboard_downloader.json_logger import JsonLogger, get_logger, log_event, new_run_id
from dashboard_downloader.report_generator import (
    StoreReportDataNotFound,
    build_store_context,
    render_store_report_pdf,
)
from dashboard_downloader.run_summary import PIPELINE_NAME, RunAggregator

DEFAULT_TEMPLATE_DIR = Path(__file__).with_name("templates")
DEFAULT_REPORTS_ROOT = Path("reports")

__all__ = [
    "resolve_report_date",
    "parse_store_list",
    "run_store_reports_for_date",
    "load_email_settings",
]


@dataclass
class EmailSettings:
    to: List[str]
    cc: List[str]
    sender: str
    subject_template: str
    host: str
    port: int
    username: str | None
    password: str | None
    use_tls: bool


def parse_store_list(raw: str | None) -> List[str]:
    if not raw:
        return []
    return [token.strip().upper() for token in raw.split(",") if token.strip()]


def resolve_report_date(arg_value: str | None = None) -> date:
    if arg_value:
        return date.fromisoformat(arg_value)
    return date.today() - timedelta(days=1)


def _parse_address_list(raw: str | None) -> List[str]:
    if not raw:
        return []
    return [token.strip() for token in raw.split(",") if token.strip()]


def load_email_settings() -> EmailSettings | None:
    to = _parse_address_list(os.getenv("REPORT_EMAIL_TO"))
    if not to:
        return None
    host = os.getenv("REPORT_EMAIL_SMTP_HOST")
    port_raw = os.getenv("REPORT_EMAIL_SMTP_PORT")
    if not host or not port_raw:
        return None
    cc = _parse_address_list(os.getenv("REPORT_EMAIL_CC"))
    sender = os.getenv("REPORT_EMAIL_FROM", "reports@tsv.com")
    subject_template = os.getenv("REPORT_EMAIL_SUBJECT_TEMPLATE", "[Store Reports] {{report_date}}").strip() or "[Store Reports] {{report_date}}"
    username = os.getenv("REPORT_EMAIL_SMTP_USERNAME")
    password = os.getenv("REPORT_EMAIL_SMTP_PASSWORD")
    use_tls = os.getenv("REPORT_EMAIL_USE_TLS", "true").lower() == "true"
    return EmailSettings(
        to=to,
        cc=cc,
        sender=sender,
        subject_template=subject_template,
        host=host,
        port=int(port_raw),
        username=username,
        password=password,
        use_tls=use_tls,
    )


def _render_subject(template: str, report_date: date) -> str:
    return template.replace("{{report_date}}", report_date.isoformat())


def build_email_message(
    settings: EmailSettings,
    report_date: date,
    pdf_records: Sequence[Tuple[str, Path]],
    *,
    body_text: str | None = None,
) -> EmailMessage:
    message = EmailMessage()
    message["Subject"] = _render_subject(settings.subject_template, report_date)
    message["From"] = settings.sender
    message["To"] = ", ".join(settings.to)
    if settings.cc:
        message["Cc"] = ", ".join(settings.cc)
    if body_text is not None:
        message.set_content(body_text)
    else:
        body_lines = [
            f"Daily store health reports for {report_date.isoformat()}.",
            "",
            "Stores:",
        ]
        body_lines.extend(f"- {store_code}" for store_code, _ in pdf_records)
        body_lines.extend(["", "Generated by TSV Simplify Downloader."])
        message.set_content("\n".join(body_lines))

    for store_code, pdf_path in pdf_records:
        attachment_name = f"{store_code}.pdf"
        data = pdf_path.read_bytes()
        message.add_attachment(
            data,
            maintype="application",
            subtype="pdf",
            filename=attachment_name,
        )
    return message


def send_email(settings: EmailSettings, message: EmailMessage) -> None:
    if settings.use_tls:
        with smtplib.SMTP(settings.host, settings.port) as client:
            client.starttls()
            if settings.username and settings.password:
                client.login(settings.username, settings.password)
            client.send_message(message)
    else:
        with smtplib.SMTP(settings.host, settings.port) as client:
            if settings.username and settings.password:
                client.login(settings.username, settings.password)
            client.send_message(message)


def get_configured_store_codes() -> List[str]:
    return parse_store_list(os.getenv("REPORT_STORES_LIST"))


def _log_skip(logger: JsonLogger) -> None:
    log_event(
        logger=logger,
        phase="report",
        status="info",
        message="no REPORT_STORES_LIST configured, skipping report generation",
    )


def _parse_args(argv: Iterable[str] | None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Generate per-store daily PDF reports")
    parser.add_argument("--report-date", dest="report_date", help="Report date (YYYY-MM-DD)")
    parser.add_argument("--run-id", dest="run_id", help="Override run id", default=None)
    parser.add_argument(
        "--template-path",
        dest="template_path",
        default=str(DEFAULT_TEMPLATE_DIR),
        help="Directory containing store_report.html",
    )
    parser.add_argument(
        "--reports-dir",
        dest="reports_dir",
        default=str(DEFAULT_REPORTS_ROOT),
        help="Directory to write generated PDFs",
    )
    return parser.parse_args(list(argv) if argv is not None else None)


async def _persist_document_record(
    *,
    database_url: str | None,
    report_date: date,
    store_code: str,
    run_id: str,
    file_name: str,
    file_path: Path | None,
    status: str,
    error_message: str | None,
    logger: JsonLogger,
) -> None:
    if not database_url:
        return

    size = None
    path_str = None
    if file_path and file_path.exists():
        size = file_path.stat().st_size
        path_str = str(file_path)

    period_reference = report_date.isoformat()
    values = {
        "doc_type": "pipeline_report",
        "doc_subtype": "store_daily_pdf",
        "doc_date": report_date,
        "reference_name_1": "pipeline_name",
        "reference_id_1": PIPELINE_NAME,
        "reference_name_2": "store_code",
        "reference_id_2": store_code,
        "reference_name_3": "report_date",
        "reference_id_3": period_reference,
        "file_name": file_name,
        "mime_type": "application/pdf",
        "file_size_bytes": size,
        "storage_backend": "fs",
        "file_path": path_str,
        "file_blob": None,
        "checksum": None,
        "status": status,
        "error_message": error_message,
        "created_by": "pipeline",
        "created_at": datetime.now(timezone.utc),
    }

    try:
        async with session_scope(database_url) as session:
            await session.execute(sa.insert(documents).values(**values))
            await session.commit()
    except Exception as exc:  # pragma: no cover - defensive
        log_event(
            logger=logger,
            phase="report",
            status="error",
            message="failed to persist document record",
            store_code=store_code,
            extras={"error": str(exc), "file_name": file_name},
        )
        return

    log_event(
        logger=logger,
        phase="report",
        status="ok",
        message="document record persisted",
        store_code=store_code,
        extras={"file_name": file_name, "file_path": path_str},
    )


async def _generate_reports(
    store_codes: Sequence[str],
    report_date: date,
    *,
    logger: JsonLogger,
    run_id: str,
    database_url: str,
    template_path: Path,
    reports_root: Path,
    aggregator: RunAggregator | None = None,
) -> List[Tuple[str, Path]]:
    generated: List[Tuple[str, Path]] = []
    for code in store_codes:
        log_event(
            logger=logger,
            phase="report",
            status="info",
            message="report generation start",
            store_code=code,
            extras={"report_date": report_date.isoformat(), "run_id": run_id},
        )
        try:
            context = await build_store_context(
                store_code=code,
                report_date=report_date,
                run_id=run_id,
                database_url=database_url,
            )
        except StoreReportDataNotFound as exc:
            log_event(
                logger=logger,
                phase="report",
                status="warning",
                message="no data available for report date",
                store_code=code,
                extras={"report_date": report_date.isoformat(), "error": str(exc)},
            )
            continue
        except Exception as exc:  # pragma: no cover - safeguard
            log_event(
                logger=logger,
                phase="report",
                status="error",
                message="failed to build report context",
                store_code=code,
                extras={"report_date": report_date.isoformat(), "error": str(exc)},
            )
            if aggregator:
                aggregator.register_pdf_failure(code, "context failure")
            continue

        output_path = reports_root / f"{report_date.year}" / f"{code}_{report_date:%m-%d}.pdf"
        try:
            await render_store_report_pdf(
                store_context=context,
                template_path=template_path,
                output_path=output_path,
            )
        except Exception as exc:  # pragma: no cover - pdf failures
            log_event(
                logger=logger,
                phase="report",
                status="error",
                message="failed to render pdf",
                store_code=code,
                extras={
                    "report_date": report_date.isoformat(),
                    "error": str(exc),
                    "output_path": str(output_path),
                },
            )
            await _persist_document_record(
                database_url=database_url,
                report_date=report_date,
                store_code=code,
                run_id=run_id,
                file_name=output_path.name,
                file_path=None,
                status="error",
                error_message=str(exc),
                logger=logger,
            )
            if aggregator:
                aggregator.register_pdf_failure(code, "render failure")
            continue

        generated.append((code, output_path))
        log_event(
            logger=logger,
            phase="report",
            status="ok",
            message="report pdf generated",
            store_code=code,
            extras={"report_date": report_date.isoformat(), "output_path": str(output_path)},
        )
        await _persist_document_record(
            database_url=database_url,
            report_date=report_date,
            store_code=code,
            run_id=run_id,
            file_name=output_path.name,
            file_path=output_path,
            status="ok",
            error_message=None,
            logger=logger,
        )
        if aggregator:
            aggregator.register_pdf_success(code, str(output_path))
    return generated


async def run_store_reports_for_date(
    report_date: date,
    *,
    logger: JsonLogger,
    run_id: str,
    database_url: str | None,
    store_codes: Sequence[str] | None = None,
    template_path: str | Path = DEFAULT_TEMPLATE_DIR,
    reports_root: str | Path = DEFAULT_REPORTS_ROOT,
) -> List[Tuple[str, Path]]:
    codes = list(store_codes) if store_codes else get_configured_store_codes()
    if not codes:
        _log_skip(logger)
        return []

    if not database_url:
        log_event(
            logger=logger,
            phase="report",
            status="error",
            message="DATABASE_URL is required for report generation",
        )
        return []

    template_dir = Path(template_path)
    reports_dir = Path(reports_root)

    aggregator: RunAggregator | None = getattr(logger, "aggregator", None)

    pdf_records = await _generate_reports(
        codes,
        report_date,
        logger=logger,
        run_id=run_id,
        database_url=database_url,
        template_path=template_dir,
        reports_root=reports_dir,
        aggregator=aggregator,
    )

    return pdf_records


async def main(argv: Iterable[str] | None = None) -> int:
    args = _parse_args(argv)
    run_id = args.run_id or new_run_id()
    logger = get_logger(run_id=run_id)

    try:
        report_date = resolve_report_date(args.report_date)
    except ValueError:
        log_event(
            logger=logger,
            phase="report",
            status="error",
            message="invalid --report-date supplied",
            extras={"value": args.report_date},
        )
        logger.close()
        return 1

    await run_store_reports_for_date(
        report_date,
        logger=logger,
        run_id=run_id,
        database_url=os.getenv("DATABASE_URL"),
        store_codes=parse_store_list(os.getenv("REPORT_STORES_LIST")),
        template_path=Path(args.template_path),
        reports_root=Path(args.reports_dir),
    )
    logger.close()
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(asyncio.run(main()))
